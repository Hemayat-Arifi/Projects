# -*- coding: utf-8 -*-
"""data_augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D24m4eH4Der5Hm_kKzubJu8p7Shs8wSQ
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout
from keras.layers.normalization.batch_normalization import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from sklearn.preprocessing import OneHotEncoder
from keras.utils import np_utils

mnist = fetch_openml('mnist_784')
x = mnist.data
y = mnist.target

feature_train, feature_test, target_train, target_test = train_test_split(x, y, test_size=0.14285)

feature_train = np.array(feature_train).reshape(60000, 28, 28)
feature_test = np.array(feature_test).reshape(10000, 28, 28)

feature_train /= 255 
feature_test /= 255

target_train = np_utils.to_categorical(target_train, 10)
target_test = np_utils.to_categorical(target_test, 10)

plt.imshow(feature_train[60], cmap="gray")
plt.title(str(target_train[60]))
plt.show()

# we changed the input shape to (28 28 1)
feature_train = np.array(feature_train).reshape(60000, 28, 28, 1)
feature_test = np.array(feature_test).reshape(10000, 28, 28, 1)

"""# **Building The CNN model**"""

model = Sequential()

model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))
model.add(Activation("relu"))
model.add(BatchNormalization())

model.add(Conv2D(32, (3, 3)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(64, (3, 3)))
model.add(Activation("relu"))
model.add(BatchNormalization())

model.add(Conv2D(64, (3, 3)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(BatchNormalization())

model.add(Dense(512))
model.add(Activation("relu"))
model.add(BatchNormalization())
model.add(Dropout(0.3))

model.add(Dense(10, activation="softmax"))

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])


# we generate new data from existing data by rotating, flipping, weigh sizing...
train_generator = ImageDataGenerator(rotation_range=7, width_shift_range=0.05, height_shift_range=0.07, zoom_range=0.05)
test_generator = ImageDataGenerator()

train_generator = train_generator.flow(feature_train, target_train, batch_size=64)
test_generator = test_generator.flow(feature_test, target_test, batch_size=64)

model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, validation_data=test_generator, validation_steps=10000//64)


# model.fit(feature_train, target_train, batch_size=128, epochs=5, validation_data=(feature_test, target_test), verbose=1)

result = model.evaluate(feature_test, target_test)

print(result[1])

for i in range(20, 30):

  predict_data = feature_train[i].reshape(-1, 28, 28)
  forcast = model.predict(predict_data)

  for item in forcast.round():
    for index, value in enumerate(item):
      if value == 1:
        print("    This is :- ", index)

  predict_data = feature_train[i].reshape(28, 28)
  plt.imshow(predict_data, cmap="gray")
  plt.show()