# -*- coding: utf-8 -*-
"""CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QrcC83a-BPPoBWt5dT16Q1o_Mh782dVb
"""

from keras.optimizer_v2.gradient_descent import SGD
import numpy as np
from keras.optimizer_v2 import adam
from keras.datasets import cifar10
from keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D, BatchNormalization
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from keras.preprocessing.image import ImageDataGenerator

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

x_train = x_train / 255.0
x_test = x_test / 255.0

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

print(y_train.shape)

# _______________________________________ Set Our Optimizer ________________________________________

opt = SGD(learning_rate=0.001, momentum=0.95)
# opt = adam.Adam(lr=0.001)

# _______________________________________ Build Our Model __________________________________________

model = Sequential()

model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation="relu", padding="same", kernel_initializer="he_uniform"))
model.add(BatchNormalization())
model.add(Conv2D(32, (3, 3), activation="relu", padding="same", kernel_initializer="he_uniform"))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))

model.add(Conv2D(64, (3, 3), activation="relu", padding="same", kernel_initializer="he_uniform"))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), activation="relu", padding="same", kernel_initializer="he_uniform"))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))

model.add(Conv2D(128, (3, 3), activation="relu", padding="same", kernel_initializer="he_uniform"))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), activation="relu", padding="same", kernel_initializer="he_uniform"))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))

model.add(Flatten())

model.add(Dense(128, activation="relu", kernel_initializer="he_uniform"))
model.add(Dropout(0.2))
model.add(Dense(10, activation="softmax"))

model.compile(optimizer=opt, loss="categorical_crossentropy", metrics=["accuracy"])

# We Use Generator to avoid overffiting and increase the dataset
# train_generator = ImageDataGenerator(rotation_range=7, height_shift_range=0.7, width_shift_range=0.5, zoom_range=0.05)
# test_generator = ImageDataGenerator()

# train_generator = train_generator.flow(x_train, y_train, batch_size=64)
# test_generator = test_generator.flow(x_test, y_test, batch_size=64)

# model.fit_generator(generator=train_generator, steps_per_epoch=50000//64, verbose=1, epochs=25, validation_data=test_generator, validation_steps=10000//64)

model.fit(x_train, y_train, epochs=50, batch_size=64, verbose=1, validation_data=(x_test, y_test))

result = model.evaluate(x_test, y_test)

print(result[0])